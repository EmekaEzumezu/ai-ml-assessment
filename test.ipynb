{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "from flask import Flask, request, render_template, jsonify, session\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_community.document_loaders import Docx2txtLoader\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_openai import OpenAI\n",
    "\n",
    "import pickle\n",
    "import shutil\n",
    "import json\n",
    "import psutil\n",
    "\n",
    "import helper_func.helper_func as helper_func\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = []\n",
    "# Iterate through files in the \"docs\" directory for processing\n",
    "for file in os.listdir(\"docs\"):\n",
    "    # Load PDF files\n",
    "    if file.endswith(\".pdf\"):\n",
    "        pdf_path = \"./docs/\" + file\n",
    "        loader = PyPDFLoader(pdf_path)\n",
    "        documents.extend(loader.load())\n",
    "    # Load Word documents\n",
    "    elif file.endswith('.docx') or file.endswith('.doc'):\n",
    "        doc_path = \"./docs/\" + file\n",
    "        loader = Docx2txtLoader(doc_path)\n",
    "        documents.extend(loader.load())\n",
    "    # Load Txt documents\n",
    "    # elif file.endswith('.txt'):\n",
    "    #     text_path = \"./docs/\" + file\n",
    "    #     loader = TextLoader(text_path)\n",
    "    #     documents.extend(loader.load())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split text into chunks for processing\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=10)\n",
    "documents = text_splitter.split_documents(documents)\n",
    "\n",
    "# Create and persist a vector database for document retrieval\n",
    "vectordb = Chroma.from_documents(documents, embedding=OpenAIEmbeddings(), persist_directory=\"./data\")\n",
    "vectordb.persist()\n",
    "\n",
    "# Set up conversational retrieval with OpenAI model\n",
    "pdf_qa = ConversationalRetrievalChain.from_llm(\n",
    "    ChatOpenAI(temperature=0.7, model_name='gpt-3.5-turbo'),\n",
    "    retriever=vectordb.as_retriever(search_kwargs={'k': 6}),\n",
    "    return_source_documents=True,\n",
    "    verbose=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 6 is greater than number of elements in index 4, updating n_results = 4\n"
     ]
    }
   ],
   "source": [
    "user_question = \"Is this person qualified for senior machine learning engineer?\"\n",
    "\n",
    "# Generate a prompt based on the user question\n",
    "query = helper_func.set_prompt_template(user_question)\n",
    "# shot += 1\n",
    "# session['shot'] = shot\n",
    "# else:\n",
    "#     query = user_question\n",
    "\n",
    "chat_history = []\n",
    "# Invoke the conversational retrieval process\n",
    "result = pdf_qa.invoke(\n",
    "    {\"question\": query, \"chat_history\": chat_history})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = str(result['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print(type(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Yes, this person is qualified for a senior machine learning engineer position based on their 5+ years of experience deploying machine learning models, conducting data analysis, and software development. They have expertise in cloud computing, data science, MLOps, LLMOps, and algorithm development. Additionally, their successful projects in developing real-time business intelligence dashboards, computer vision solutions, and machine learning models demonstrate their proficiency.\n",
      "\n",
      "2. ['5+ years of experience in deploying ML models', 'Expertise in cloud computing and algorithm development', 'Successful projects in business intelligence and computer vision', 'Proficient in Python, SQL, and diverse ML frameworks']\n",
      "\n",
      "3. Random question: What are the key skills and technologies mentioned in the person's profile that showcase their expertise in machine learning engineering?\n",
      "\n",
      "4. test_answer: The key skills and technologies that showcase the person's expertise in machine learning engineering include FastAPI, Modelling, TensorFlow, ETL, NLP, Scikit-learn, Clustering, Data Processing, and Data Visualization.\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: Yes, this person is qualified for a senior machine learning engineer position based on their 5+ years of experience deploying machine learning models, conducting data analysis, and software development. They have expertise in cloud computing, data science, MLOps, LLMOps, and algorithm development. Additionally, their successful projects in developing real-time business intelligence dashboards, computer vision solutions, and machine learning models demonstrate their proficiency.\n",
      "Bullet Points: ['5+ years of experience in deploying ML models', 'Expertise in cloud computing and algorithm development', 'Successful projects in business intelligence and computer vision', 'Proficient in Python, SQL, and diverse ML frameworks']\n",
      "Test Question: Random question: What are the key skills and technologies mentioned in the person's profile that showcase their expertise in machine learning engineering?\n",
      "Test Answer: er: The key skills and technologies that showcase the person's expertise in machine learning engineering include FastAPI, Modelling, TensorFlow, ETL, NLP, Scikit-learn, Clustering, Data Processing, and Data Visualization.\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "\n",
    "# Split the string by the numbers\n",
    "sections = results.split('\\n\\n')\n",
    "\n",
    "# Assign each section to a separate variable\n",
    "answer = sections[0][3:].strip()  # Remove the numbering and leading/trailing whitespace\n",
    "bullet_points = ast.literal_eval(sections[1][3:].strip())\n",
    "test_question = sections[2][3:].strip()\n",
    "test_answer = sections[3][12:].strip()  # Remove the \"Test_answer: \" prefix and leading/trailing whitespace\n",
    "\n",
    "# Print the variables\n",
    "print(\"Answer:\", answer)\n",
    "print(\"Bullet Points:\", bullet_points)\n",
    "print(\"Test Question:\", test_question)\n",
    "print(\"Test Answer:\", test_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(bullet_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 6 is greater than number of elements in index 4, updating n_results = 4\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the test answer from the session\n",
    "user_answer = \"FastAPI, Modelling, Deployment and Monitoring, CI/CD pipelines (GitHub Action), Docker Container, Appservice\"\n",
    "\n",
    "# Generate a prompt based on the user's answer and test answer\n",
    "query = helper_func.set_eval_prompt_template(user_answer, test_answer)\n",
    "\n",
    "chat_history = []\n",
    "# Invoke the conversational retrieval process\n",
    "result = pdf_qa.invoke(\n",
    "    {\"question\": query, \"chat_history\": chat_history})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'True'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the answer from the result to a string\n",
    "results = str(result[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "90\n"
     ]
    }
   ],
   "source": [
    "# Split the string by comma\n",
    "values = results.split(\", \")\n",
    "\n",
    "# Convert knowledge_understood to bool\n",
    "knowledge_understood = bool(values[0])\n",
    "\n",
    "# Remove percentage sign and convert knowledge_confidence to int\n",
    "knowledge_confidence = int(values[1].rstrip(\"%\"))\n",
    "\n",
    "print(knowledge_understood)  # Output: True\n",
    "print(knowledge_confidence)  # Output: 90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bool"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(knowledge_understood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "try:\n",
    "    # Split the string by comma\n",
    "    if results.split(\", \"):\n",
    "        values = results.split(\", \")\n",
    "\n",
    "        # Convert knowledge_understood to bool\n",
    "        knowledge_understood = bool(values[0])\n",
    "\n",
    "        # Remove percentage sign and convert knowledge_confidence to int\n",
    "        knowledge_confidence = int(values[1].rstrip(\"%\"))\n",
    "    else:\n",
    "        # Convert knowledge_understood to bool\n",
    "        knowledge_understood = bool(results)\n",
    "\n",
    "        knowledge_confidence = 0\n",
    "\n",
    "except:\n",
    "    # Assign default values\n",
    "    knowledge_understood = False\n",
    "    knowledge_confidence = 0\n",
    "\n",
    "print(knowledge_understood)  # Output: True\n",
    "print(knowledge_confidence)  # Output: 90\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nurovant",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
