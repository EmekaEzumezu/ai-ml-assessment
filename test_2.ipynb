{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG Search Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import DocArrayInMemorySearch\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arinz\\anaconda3\\envs\\assessment\\lib\\site-packages\\pydantic\\_migration.py:283: UserWarning: `pydantic.error_wrappers:ValidationError` has been moved to `pydantic:ValidationError`.\n",
      "  warnings.warn(f'`{import_path}` has been moved to `{new_location}`.')\n"
     ]
    }
   ],
   "source": [
    "vectorstore = DocArrayInMemorySearch.from_texts(\n",
    "    [\"harrison worked at kensho\", \"bears like to eat honey\"],\n",
    "    embedding=OpenAIEmbeddings(),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "model = ChatOpenAI()\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_and_retrieval = RunnableParallel(\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    ")\n",
    "chain = setup_and_retrieval | prompt | model | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = chain.invoke(\"where did harrison work?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Harrison worked at Kensho.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JSON parsar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your desired data structure.\n",
    "class Joke(BaseModel):\n",
    "    setup: str = Field(description=\"question to set up a joke\")\n",
    "    punchline: str = Field(description=\"answer to resolve the joke\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And a query intented to prompt a language model to populate the data structure.\n",
    "joke_query = \"Tell me a joke.\"\n",
    "\n",
    "# Set up a parser + inject instructions into the prompt template.\n",
    "parser = JsonOutputParser(pydantic_object=Joke)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "chain = prompt | model | parser\n",
    "\n",
    "result = chain.invoke({\"query\": joke_query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'setup': \"Why couldn't the bicycle stand up by itself?\",\n",
       " 'punchline': 'Because it was two tired!'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AI ML Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_community.document_loaders import Docx2txtLoader\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "# from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "# from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = []\n",
    "# Iterate through files in the \"docs\" directory for processing\n",
    "for file in os.listdir(\"docs\"):\n",
    "    # Load PDF files\n",
    "    if file.endswith(\".pdf\"):\n",
    "        pdf_path = \"./docs/\" + file\n",
    "        loader = PyPDFLoader(pdf_path)\n",
    "        documents.extend(loader.load())\n",
    "    # Load Word documents\n",
    "    elif file.endswith('.docx') or file.endswith('.doc'):\n",
    "        doc_path = \"./docs/\" + file\n",
    "        loader = Docx2txtLoader(doc_path)\n",
    "        documents.extend(loader.load())\n",
    "    # Load Txt documents\n",
    "    # elif file.endswith('.txt'):\n",
    "    #     text_path = \"./docs/\" + file\n",
    "    #     loader = TextLoader(text_path)\n",
    "    #     documents.extend(loader.load())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Split document into chunks\n",
    "# text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "# texts = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #This is used to split text based on chunk_size provided.\n",
    "# from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "# text_splitter = RecursiveCharacterTextSplitter(chunk_size = 500, chunk_overlap = 0)\n",
    "# all_splits = text_splitter.split_documents(data)# Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split text into chunks for processing\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=10)\n",
    "documents = text_splitter.split_documents(documents)\n",
    "\n",
    "# Create and persist a vector database for document retrieval\n",
    "vectordb = Chroma.from_documents(documents, embedding=OpenAIEmbeddings())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectordb.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(temperature=0)\n",
    "# model = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your desired data structure.\n",
    "# class Joke(BaseModel):\n",
    "#     setup: str = Field(description=\"question to set up a joke\")\n",
    "#     punchline: str = Field(description=\"answer to resolve the joke\")\n",
    "\n",
    "class Joke(BaseModel):\n",
    "    answer: str = Field(description=\"The answer provided by the system to the question asked\")\n",
    "    bullet_points: list = Field(description=\"A list of bullet points emphasizing key details in the answer to improve understanding\")\n",
    "    test_question: str = Field(description=\"Generated question to evaluate if the user understood the answer provided\")\n",
    "    test_answer: str = Field(description=\"Generate an answer which will be used to evaluate the user answer for the generated question\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And a query intented to prompt a language model to populate the data structure.\n",
    "joke_query = \"Who is the CV about?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a parser + inject instructions into the prompt template.\n",
    "parser = JsonOutputParser(pydantic_object=Joke)\n",
    "\n",
    "# prompt = PromptTemplate(\n",
    "#     template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
    "#     input_variables=[\"query\"],\n",
    "#     partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the user query.\\n{context}\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions(), \"context\": documents},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorstore = DocArrayInMemorySearch.from_texts(\n",
    "#     [\"harrison worked at kensho\", \"bears like to eat honey\"],\n",
    "#     embedding=OpenAIEmbeddings(),\n",
    "# )\n",
    "# retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_and_retrieval = RunnableParallel(\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    ")\n",
    "\n",
    "# chain = setup_and_retrieval | prompt | model | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_and_retrieval = RunnableParallel(\n",
    "    {\"context\": retriever}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# template = \"\"\"Answer the question based only on the following context:\n",
    "# {context}\n",
    "\n",
    "# Question: {question}\n",
    "# \"\"\"\n",
    "# prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "# parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables.base import RunnableParallel\n",
    "from langchain_core.runnables.pass_through import RunnablePassthrough\n",
    "from langchain_core.runnables.json_output_parser import JsonOutputParser\n",
    "\n",
    "# Assuming you have a retriever runnable defined as 'retriever'\n",
    "retriever = ...\n",
    "\n",
    "# Set up RunnableParallel with JsonOutputParser\n",
    "setup_and_retrieval = RunnableParallel(\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()},\n",
    "    output_parsers={\"context\": JsonOutputParser(), \"question\": JsonOutputParser()}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables.base import BaseRunnable\n",
    "\n",
    "class RunnablePassthrough(BaseRunnable):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def invoke(self, input, config):\n",
    "        return input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | model | parser\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = chain.invoke({\"query\": joke_query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = chain.invoke(\"Who is the CV about?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer': 'The CV is about Chukwuemeka Ezumezu, a Lead Machine Learning Engineer with expertise in deploying machine learning models, conducting data analysis, and software development.',\n",
       " 'bullet_points': ['Results-driven Lead Machine Learning Engineer with 5+ years of experience',\n",
       "  'Specializes in cloud computing, data science, MLOps, LLMOps, and algorithm development',\n",
       "  'Proficient in Python, SQL, and diverse machine learning frameworks',\n",
       "  'Demonstrated success in optimizing business strategies through data-driven insights'],\n",
       " 'test_question': 'What is the main expertise of Chukwuemeka Ezumezu?',\n",
       " 'test_answer': \"Chukwuemeka Ezumezu's main expertise is in deploying machine learning models, conducting data analysis, and software development.\"}"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer': 'The CV is about John Doe, a seasoned software engineer with over 10 years of experience in the industry.',\n",
       " 'bullet_points': ['John has worked at top tech companies such as Google and Microsoft.',\n",
       "  'He specializes in backend development and has expertise in Java, Python, and SQL.',\n",
       "  \"John holds a Master's degree in Computer Science from Stanford University.\"],\n",
       " 'test_question': \"What is John Doe's area of expertise?\",\n",
       " 'test_answer': 'John Doe specializes in backend development and has expertise in Java, Python, and SQL.'}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nurovant",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
